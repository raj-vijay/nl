{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "05. NLP 5 - FastText.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPEeFJR+TFrX2kMsVMcgXj1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/raj-vijay/nl/blob/master/05.%20Understanding_Emotions_in_Tweets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDbwtwJIozCQ"
      },
      "source": [
        "**fastText**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQUfamizgREh"
      },
      "source": [
        "<p align = 'justify'>fastText (https://pypi.org/project/fasttext/) is a library for efficient learning of word representations and sentence classification.\n",
        "\n",
        "In this Lab, you will train and test FastText text classifier mainly using\n",
        "the train_supervised, which returns a model object, and call test and predict on this object.</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4ZS5ologbtw"
      },
      "source": [
        "**Data**\n",
        "\n",
        "We are interested in building a classifier to automatically recognize the topic of a stackexchange question about cooking. Let's download examples of questions \n",
        "from the cooking section of Stackexchange (https://cooking.stackexchange.com/), and their associated tags:\n",
        "\n",
        ">> wget https://dl.fbaipublicfiles.com/fasttext/data/cooking.stackexchange.tar.gz && tar xvzf cooking.stackexchange.tar.gz\n",
        ">> head cooking.stackexchange.txt\n",
        "\n",
        "Each line of the text file contains a list of labels, followed by the corresponding document. All the labels start by the __label__ prefix, which is how fastText recognize what is a label or what is a word. The model is then trained to predict the labels given the word in the document.\n",
        "\n",
        "Before training our first classifier, we need to split the data into train and validation. We will use the validation set to evaluate how good the learned classifier is on new data.\n",
        "\n",
        ">> wc cooking.stackexchange.txt\n",
        "\n",
        "Our full dataset contains 15404 examples. Let's split it into a training set of 12404 examples and a validation set of 3000 examples:\n",
        "\n",
        ">> head -n 12404 cooking.stackexchange.txt > cooking.train\n",
        ">> tail -n 3000 cooking.stackexchange.txt > cooking.valid"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92_YzDONfrXE",
        "outputId": "49b55aab-a9ec-4ee7-a607-a1bff4cbbe1f"
      },
      "source": [
        "! wget https://dl.fbaipublicfiles.com/fasttext/data/cooking.stackexchange.tar.gz && tar xvzf cooking.stackexchange.tar.gz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-25 12:33:44--  https://dl.fbaipublicfiles.com/fasttext/data/cooking.stackexchange.tar.gz\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 172.67.9.4, 104.22.75.142, 104.22.74.142, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|172.67.9.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 457609 (447K) [application/x-tar]\n",
            "Saving to: ‘cooking.stackexchange.tar.gz’\n",
            "\n",
            "cooking.stackexchan 100%[===================>] 446.88K  1.19MB/s    in 0.4s    \n",
            "\n",
            "2021-05-25 12:33:45 (1.19 MB/s) - ‘cooking.stackexchange.tar.gz’ saved [457609/457609]\n",
            "\n",
            "cooking.stackexchange.id\n",
            "cooking.stackexchange.txt\n",
            "readme.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PAZ_JL59hF-j",
        "outputId": "5c4172da-661a-4790-f9a4-cb1509591cdb"
      },
      "source": [
        "!head cooking.stackexchange.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__label__sauce __label__cheese How much does potato starch affect a cheese sauce recipe?\n",
            "__label__food-safety __label__acidity Dangerous pathogens capable of growing in acidic environments\n",
            "__label__cast-iron __label__stove How do I cover up the white spots on my cast iron stove?\n",
            "__label__restaurant Michelin Three Star Restaurant; but if the chef is not there\n",
            "__label__knife-skills __label__dicing Without knife skills, how can I quickly and accurately dice vegetables?\n",
            "__label__storage-method __label__equipment __label__bread What's the purpose of a bread box?\n",
            "__label__baking __label__food-safety __label__substitutions __label__peanuts how to seperate peanut oil from roasted peanuts at home?\n",
            "__label__chocolate American equivalent for British chocolate terms\n",
            "__label__baking __label__oven __label__convection Fan bake vs bake\n",
            "__label__sauce __label__storage-lifetime __label__acidity __label__mayonnaise Regulation and balancing of readymade packed mayonnaise and other sauces\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GjUid8YIhP-L",
        "outputId": "a8a6289f-2571-4cc4-a033-55d6cb7605b6"
      },
      "source": [
        "!wc cooking.stackexchange.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  15404  169582 1401900 cooking.stackexchange.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LWmFjvthT8A"
      },
      "source": [
        "!head -n 12404 cooking.stackexchange.txt > cooking.train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oh69MWZJhW65"
      },
      "source": [
        "!tail -n 3000 cooking.stackexchange.txt > cooking.valid"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_m_Jz3Ehhhl"
      },
      "source": [
        "**Installation**\n",
        "\n",
        "FastText builds on modern Mac OS and Linux distributions. Since it uses C++11 \n",
        "features, it requires a compiler with good C++11 support. You will \n",
        "need Python (version 2.7 or ≥ 3.4), NumPy & SciPy and pybind11"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VSDgP1M8hcv0",
        "outputId": "bd9bf59a-083f-4068-b761-d86d62d8dd40"
      },
      "source": [
        "!pip install fasttext"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting fasttext\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f8/85/e2b368ab6d3528827b147fdb814f8189acc981a4bc2f99ab894650e05c40/fasttext-0.9.2.tar.gz (68kB)\n",
            "\r\u001b[K     |████▊                           | 10kB 11.0MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 20kB 14.7MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 30kB 18.4MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 40kB 13.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 51kB 5.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 61kB 5.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 3.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.7/dist-packages (from fasttext) (2.6.2)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from fasttext) (56.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fasttext) (1.19.5)\n",
            "Building wheels for collected packages: fasttext\n",
            "  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.2-cp37-cp37m-linux_x86_64.whl size=3094722 sha256=5dda1a8b341f60199478bf8645c15b810dc3fa54a4f860de2e2ff50ad8aed7bb\n",
            "  Stored in directory: /root/.cache/pip/wheels/98/ba/7f/b154944a1cf5a8cee91c154b75231136cc3a3321ab0e30f592\n",
            "Successfully built fasttext\n",
            "Installing collected packages: fasttext\n",
            "Successfully installed fasttext-0.9.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6oP582-HmsYB"
      },
      "source": [
        "import fasttext"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mg8f4Xgsmzq3",
        "outputId": "a2dabe79-4e21-4508-a9c5-c90555f08960"
      },
      "source": [
        "help(fasttext.FastText)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Help on module fasttext.FastText in fasttext:\n",
            "\n",
            "NAME\n",
            "    fasttext.FastText\n",
            "\n",
            "DESCRIPTION\n",
            "    # Copyright (c) 2017-present, Facebook, Inc.\n",
            "    # All rights reserved.\n",
            "    #\n",
            "    # This source code is licensed under the MIT license found in the\n",
            "    # LICENSE file in the root directory of this source tree.\n",
            "\n",
            "FUNCTIONS\n",
            "    cbow(*kargs, **kwargs)\n",
            "    \n",
            "    eprint(*args, **kwargs)\n",
            "    \n",
            "    load_model(path)\n",
            "        Load a model given a filepath and return a model object.\n",
            "    \n",
            "    read_args(arg_list, arg_dict, arg_names, default_values)\n",
            "    \n",
            "    skipgram(*kargs, **kwargs)\n",
            "    \n",
            "    supervised(*kargs, **kwargs)\n",
            "    \n",
            "    tokenize(text)\n",
            "        Given a string of text, tokenize it and return a list of tokens\n",
            "    \n",
            "    train_supervised(*kargs, **kwargs)\n",
            "        Train a supervised model and return a model object.\n",
            "        \n",
            "        input must be a filepath. The input text does not need to be tokenized\n",
            "        as per the tokenize function, but it must be preprocessed and encoded\n",
            "        as UTF-8. You might want to consult standard preprocessing scripts such\n",
            "        as tokenizer.perl mentioned here: http://www.statmt.org/wmt07/baseline.html\n",
            "        \n",
            "        The input file must must contain at least one label per line. For an\n",
            "        example consult the example datasets which are part of the fastText\n",
            "        repository such as the dataset pulled by classification-example.sh.\n",
            "    \n",
            "    train_unsupervised(*kargs, **kwargs)\n",
            "        Train an unsupervised model and return a model object.\n",
            "        \n",
            "        input must be a filepath. The input text does not need to be tokenized\n",
            "        as per the tokenize function, but it must be preprocessed and encoded\n",
            "        as UTF-8. You might want to consult standard preprocessing scripts such\n",
            "        as tokenizer.perl mentioned here: http://www.statmt.org/wmt07/baseline.html\n",
            "        \n",
            "        The input field must not contain any labels or use the specified label prefix\n",
            "        unless it is ok for those words to be ignored. For an example consult the\n",
            "        dataset pulled by the example script word-vector-example.sh, which is\n",
            "        part of the fastText repository.\n",
            "\n",
            "DATA\n",
            "    BOW = '<'\n",
            "    EOS = '</s>'\n",
            "    EOW = '>'\n",
            "    absolute_import = _Feature((2, 5, 0, 'alpha', 1), (3, 0, 0, 'alpha', 0...\n",
            "    displayed_errors = {}\n",
            "    division = _Feature((2, 2, 0, 'alpha', 2), (3, 0, 0, 'alpha', 0), 8192...\n",
            "    print_function = _Feature((2, 6, 0, 'alpha', 2), (3, 0, 0, 'alpha', 0)...\n",
            "    unicode_literals = _Feature((2, 6, 0, 'alpha', 2), (3, 0, 0, 'alpha', ...\n",
            "    unsupervised_default = {'autotuneDuration': 300, 'autotuneMetric': 'f1...\n",
            "\n",
            "FILE\n",
            "    /usr/local/lib/python3.7/dist-packages/fasttext/FastText.py\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z11y0BLHnNz5"
      },
      "source": [
        "**Preprocessing the data**\n",
        "\n",
        "Looking at the data, we observe that some words contain uppercase letter or \n",
        "punctuation. One of the first step to improve the performance of our model is to apply some simple pre-processing. A crude normalization can be obtained using command line tools such as sed and tr:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BEmbSr7ym359"
      },
      "source": [
        "!cat cooking.stackexchange.txt | sed -e \"s/\\([.\\!?,'/()]\\)/ \\1 /g\" | tr \"[:upper:]\" \"[:lower:]\" > cooking.preprocessed.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AH0Ewdb2nAm7"
      },
      "source": [
        "!head -n 12404 cooking.preprocessed.txt > cooking.train\n",
        "!tail -n 3000 cooking.preprocessed.txt > cooking.valid"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQ21oGr_npmh"
      },
      "source": [
        "Let's train a new model on the pre-processed data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MawQvM68nCjy"
      },
      "source": [
        "model = fasttext.train_supervised(input=\"cooking.train\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wv4g1sVnspX"
      },
      "source": [
        "<p align = 'justify'>By default, fastText sees each training example only five times during training, which is pretty small, given that our training set only have 12k training examples. The number of times each examples is seen (also known as the number of epochs), can be increased using the -epoch option:</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWf5UmUsnJtK"
      },
      "source": [
        "model = fasttext.train_supervised(input=\"cooking.train\", epoch=25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbLbRvo7n5qQ"
      },
      "source": [
        "<p align = 'justify'>You can improve the performance of a model by using word bigrams, instead of just unigrams. This is especially important for classification problems where word order is important, such as sentiment analysis.</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tB_1WBp3oAFt"
      },
      "source": [
        "model = fasttext.train_supervised(input=\"cooking.train\", lr=1.0, epoch=25, wordNgrams=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXgEER-ooD9p"
      },
      "source": [
        "<p align = 'justify'>You need to apply the different training configuration explained above and compare the results by evaluating these systems using the following command:</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kLlh6G3UoKcq",
        "outputId": "bc670c9f-28e3-4f7e-e44c-7570e28c42b0"
      },
      "source": [
        "model.test(\"cooking.valid\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3000, 0.5996666666666667, 0.2593340060544904)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    }
  ]
}
