{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Working with spaCy.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMsBso8k9Su9lmbzZPL9yxI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/raj-vijay/nl/blob/master/14_Working_with_spaCy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWmdTT91kPS9"
      },
      "source": [
        "Here, we clean the text into a more machine friendly format. This will involve converting to lowercase, lemmatization and removing stopwords, punctuations and non-alphabetic characters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-UO82AnjJAU"
      },
      "source": [
        "with open('blog.txt', 'r') as f:\n",
        "    blog = f.read()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "OtDJxHI0jcAc",
        "outputId": "2a4878ca-04a0-4b0c-96b6-f30b0eab18c6"
      },
      "source": [
        "blog[:100]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Twenty-first-century politics has witnessed an alarming rise of populism in the U.S. and Europe. The'"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A04VBaA7jnG0"
      },
      "source": [
        "import spacy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6sZDusAj9i2"
      },
      "source": [
        "stopwords = ['fifteen', 'noone', 'whereupon', 'could', 'ten', 'all', 'please', 'indeed', 'whole', 'beside', 'therein', 'using', 'but', 'very', 'already', 'about', 'no', 'regarding', 'afterwards', 'front', 'go', 'in', 'make', 'three', 'here', 'what', 'without', 'yourselves', 'which', 'nothing', 'am', 'between', 'along', 'herein', 'sometimes', 'did', 'as', 'within', 'elsewhere', 'was', 'forty', 'becoming', 'how', 'will', 'other', 'bottom', 'these', 'amount', 'across', 'the', 'than', 'first', 'namely', 'may', 'none', 'anyway', 'again', 'eleven', 'his', 'meanwhile', 'name', 're', 'from', 'some', 'thru', 'upon', 'whither', 'he', 'such', 'down', 'my', 'often', 'whether', 'made', 'while', 'empty', 'two', 'latter', 'whatever', 'cannot', 'less', 'many', 'you', 'ours', 'done', 'thus', 'since', 'everything', 'for', 'more', 'unless', 'former', 'anyone', 'per', 'seeming', 'hereafter', 'on', 'yours', 'always', 'due', 'last', 'alone', 'one', 'something', 'twenty', 'until', 'latterly', 'seems', 'were', 'where', 'eight', 'ourselves', 'further', 'themselves', 'therefore', 'they', 'whenever', 'after', 'among', 'when', 'at', 'through', 'put', 'thereby', 'then', 'should', 'formerly', 'third', 'who', 'this', 'neither', 'others', 'twelve', 'also', 'else', 'seemed', 'has', 'ever', 'someone', 'its', 'that', 'does', 'sixty', 'why', 'do', 'whereas', 'are', 'either', 'hereupon', 'rather', 'because', 'might', 'those', 'via', 'hence', 'itself', 'show', 'perhaps', 'various', 'during', 'otherwise', 'thereafter', 'yourself', 'become', 'now', 'same', 'enough', 'been', 'take', 'their', 'seem', 'there', 'next', 'above', 'mostly', 'once', 'a', 'top', 'almost', 'six', 'every', 'nobody', 'any', 'say', 'each', 'them', 'must', 'she', 'throughout', 'whence', 'hundred', 'not', 'however', 'together', 'several', 'myself', 'i', 'anything', 'somehow', 'or', 'used', 'keep', 'much', 'thereupon', 'ca', 'just', 'behind', 'can', 'becomes', 'me', 'had', 'only', 'back', 'four', 'somewhere', 'if', 'by', 'whereafter', 'everywhere', 'beforehand', 'well', 'doing', 'everyone', 'nor', 'five', 'wherein', 'so', 'amongst', 'though', 'still', 'move', 'except', 'see', 'us', 'your', 'against', 'although', 'is', 'became', 'call', 'have', 'most', 'wherever', 'few', 'out', 'whom', 'yet', 'be', 'own', 'off', 'quite', 'with', 'and', 'side', 'whoever', 'would', 'both', 'fifty', 'before', 'full', 'get', 'sometime', 'beyond', 'part', 'least', 'besides', 'around', 'even', 'whose', 'hereby', 'up', 'being', 'we', 'an', 'him', 'below', 'moreover', 'really', 'it', 'of', 'our', 'nowhere', 'whereby', 'too', 'her', 'toward', 'anyhow', 'give', 'never', 'another', 'anywhere', 'mine', 'herself', 'over', 'himself', 'to', 'onto', 'into', 'thence', 'towards', 'hers', 'nevertheless', 'serious', 'under', 'nine']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VD3ZTdXJjiOq"
      },
      "source": [
        "# Load model and create Doc object\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "doc = nlp(blog)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKJGjptijp3h"
      },
      "source": [
        "# Generate lemmatized tokens\n",
        "lemmas = [token.lemma_ for token in doc]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cq2ib0u3jsZw"
      },
      "source": [
        "# Remove stopwords and non-alphabetic tokens\n",
        "a_lemmas = [lemma for lemma in lemmas if lemma.isalpha() and lemma not in stopwords]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6QZBnzHtj_3h",
        "outputId": "276f4a26-15fc-4188-ab63-7c873456b8e2"
      },
      "source": [
        "# Print string after text cleaning\n",
        "print(' '.join(a_lemmas))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "century politic witness alarming rise populism Europe warning sign come UK Brexit Referendum vote swinging way Leave follow stupendous victory billionaire Donald Trump President United States November Europe steady rise populist far right party capitalize Europe Immigration Crisis raise nationalist anti europe sentiment instance include alternative Germany AfD win seat enter Bundestag upset Germany political order time Second World War success Star Movement Italy surge popularity neo nazism neo fascism country Hungary Czech Republic Poland Austria\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3LHpP_ryQ5P"
      },
      "source": [
        "**POS tagging**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m60FdVGjyXk9"
      },
      "source": [
        "Here we perform part-of-speech tagging"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wnjr7hbqyFAL",
        "outputId": "0a5bf35d-712c-45ae-cbf9-8821d387b7e3"
      },
      "source": [
        "# Generate tokens and pos tags\n",
        "pos = [(token.text, token.pos_) for token in doc]\n",
        "print(pos)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Twenty', 'NUM'), ('-', 'PUNCT'), ('first', 'ADJ'), ('-', 'PUNCT'), ('century', 'NOUN'), ('politics', 'NOUN'), ('has', 'AUX'), ('witnessed', 'VERB'), ('an', 'DET'), ('alarming', 'ADJ'), ('rise', 'NOUN'), ('of', 'ADP'), ('populism', 'NOUN'), ('in', 'ADP'), ('the', 'DET'), ('U.S.', 'PROPN'), ('and', 'CCONJ'), ('Europe', 'PROPN'), ('.', 'PUNCT'), ('The', 'DET'), ('first', 'ADJ'), ('warning', 'NOUN'), ('signs', 'NOUN'), ('came', 'VERB'), ('with', 'ADP'), ('the', 'DET'), ('UK', 'PROPN'), ('Brexit', 'PROPN'), ('Referendum', 'PROPN'), ('vote', 'NOUN'), ('in', 'ADP'), ('2016', 'NUM'), ('swinging', 'NOUN'), ('in', 'ADP'), ('the', 'DET'), ('way', 'NOUN'), ('of', 'ADP'), ('Leave', 'PROPN'), ('.', 'PUNCT'), ('This', 'DET'), ('was', 'AUX'), ('followed', 'VERB'), ('by', 'ADP'), ('a', 'DET'), ('stupendous', 'ADJ'), ('victory', 'NOUN'), ('by', 'ADP'), ('billionaire', 'NOUN'), ('Donald', 'PROPN'), ('Trump', 'PROPN'), ('to', 'PART'), ('become', 'VERB'), ('the', 'DET'), ('45th', 'ADJ'), ('President', 'PROPN'), ('of', 'ADP'), ('the', 'DET'), ('United', 'PROPN'), ('States', 'PROPN'), ('in', 'ADP'), ('November', 'PROPN'), ('2016', 'NUM'), ('.', 'PUNCT'), ('Since', 'SCONJ'), ('then', 'ADV'), (',', 'PUNCT'), ('Europe', 'PROPN'), ('has', 'AUX'), ('seen', 'VERB'), ('a', 'DET'), ('steady', 'ADJ'), ('rise', 'NOUN'), ('in', 'ADP'), ('populist', 'NOUN'), ('and', 'CCONJ'), ('far', 'ADJ'), ('-', 'PUNCT'), ('right', 'ADJ'), ('parties', 'NOUN'), ('that', 'DET'), ('have', 'AUX'), ('capitalized', 'VERB'), ('on', 'ADP'), ('Europe', 'PROPN'), ('â€™s', 'PART'), ('Immigration', 'PROPN'), ('Crisis', 'PROPN'), ('to', 'PART'), ('raise', 'VERB'), ('nationalist', 'ADJ'), ('and', 'CCONJ'), ('anti', 'ADJ'), ('-', 'ADJ'), ('Europe', 'ADJ'), ('sentiments', 'NOUN'), ('.', 'PUNCT'), ('Some', 'DET'), ('instances', 'NOUN'), ('include', 'VERB'), ('Alternative', 'NOUN'), ('for', 'ADP'), ('Germany', 'PROPN'), ('(', 'PUNCT'), ('AfD', 'PROPN'), (')', 'PUNCT'), ('winning', 'VERB'), ('12.6', 'NUM'), ('%', 'NOUN'), ('of', 'ADP'), ('all', 'DET'), ('seats', 'NOUN'), ('and', 'CCONJ'), ('entering', 'VERB'), ('the', 'DET'), ('Bundestag', 'PROPN'), (',', 'PUNCT'), ('thus', 'ADV'), ('upsetting', 'VERB'), ('Germany', 'PROPN'), ('â€™s', 'PART'), ('political', 'ADJ'), ('order', 'NOUN'), ('for', 'ADP'), ('the', 'DET'), ('first', 'ADJ'), ('time', 'NOUN'), ('since', 'SCONJ'), ('the', 'DET'), ('Second', 'PROPN'), ('World', 'PROPN'), ('War', 'PROPN'), (',', 'PUNCT'), ('the', 'DET'), ('success', 'NOUN'), ('of', 'ADP'), ('the', 'DET'), ('Five', 'NUM'), ('Star', 'PROPN'), ('Movement', 'PROPN'), ('in', 'ADP'), ('Italy', 'PROPN'), ('and', 'CCONJ'), ('the', 'DET'), ('surge', 'NOUN'), ('in', 'ADP'), ('popularity', 'NOUN'), ('of', 'ADP'), ('neo', 'PROPN'), ('-', 'PUNCT'), ('nazism', 'PROPN'), ('and', 'CCONJ'), ('neo', 'PROPN'), ('-', 'PUNCT'), ('fascism', 'PROPN'), ('in', 'ADP'), ('countries', 'NOUN'), ('such', 'ADJ'), ('as', 'SCONJ'), ('Hungary', 'PROPN'), (',', 'PUNCT'), ('Czech', 'PROPN'), ('Republic', 'PROPN'), (',', 'PUNCT'), ('Poland', 'PROPN'), ('and', 'CCONJ'), ('Austria', 'PROPN'), ('.', 'PUNCT')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dU6Kx3FylN1"
      },
      "source": [
        "**Counting nouns**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4eWzypuzyylF"
      },
      "source": [
        "# Returns number of proper nouns\n",
        "def proper_nouns(text, model=nlp):\n",
        "  \t# Create doc object\n",
        "    doc = model(text)\n",
        "    # Generate list of POS tags\n",
        "    pos = [token.pos_ for token in doc]\n",
        "    \n",
        "    # Return number of proper nouns\n",
        "    return pos.count('PROPN')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PBpzwVxjyzeM",
        "outputId": "60245b82-db58-466e-c186-2089a1633ae3"
      },
      "source": [
        "print(proper_nouns(\"Abdul, Bill and Cathy went to the market to buy apples.\", nlp))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dABf4fEprUcD"
      },
      "source": [
        "**POS Tagging in Lord of the Flies**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1nruYQfxRIu"
      },
      "source": [
        "lotf = 'He found himself understanding the wearisomeness of this life, where every path was an improvisation and a considerable part of oneâ€™s waking life was spent watching oneâ€™s feet.'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Msuzz3X8xTk1"
      },
      "source": [
        "# Create a Doc object\n",
        "doc = nlp(lotf)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fwdSEqI4xWkX",
        "outputId": "5ce2bb23-bb20-4c9c-dada-8370e1c3e5d4"
      },
      "source": [
        "# Generate tokens and pos tags\n",
        "pos = [(token.text, token.pos_) for token in doc]\n",
        "print(pos)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('He', 'PRON'), ('found', 'VERB'), ('himself', 'PRON'), ('understanding', 'VERB'), ('the', 'DET'), ('wearisomeness', 'NOUN'), ('of', 'ADP'), ('this', 'DET'), ('life', 'NOUN'), (',', 'PUNCT'), ('where', 'ADV'), ('every', 'DET'), ('path', 'NOUN'), ('was', 'AUX'), ('an', 'DET'), ('improvisation', 'NOUN'), ('and', 'CCONJ'), ('a', 'DET'), ('considerable', 'ADJ'), ('part', 'NOUN'), ('of', 'ADP'), ('one', 'NUM'), ('â€™s', 'PART'), ('waking', 'VERB'), ('life', 'NOUN'), ('was', 'AUX'), ('spent', 'VERB'), ('watching', 'VERB'), ('one', 'PRON'), ('â€™s', 'PART'), ('feet', 'NOUN'), ('.', 'PUNCT')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fwon-SYix00B"
      },
      "source": [
        "**Named entities in a sentence**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8f3x6SE8x3zK"
      },
      "source": [
        "# Load the required model\n",
        "nlp = spacy.load('en_core_web_sm')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44hV2ssSx569"
      },
      "source": [
        "# Create a Doc instance \n",
        "text = 'Sundar Pichai is the CEO of Google. Its headquarters is in Mountain View.'\n",
        "doc = nlp(text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l9jmou4Xx710",
        "outputId": "94553068-f01d-401d-9db6-118e05096323"
      },
      "source": [
        "# Print all named entities and their labels\n",
        "for ent in doc.ents:\n",
        "    print(ent.text, ent.label_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sundar Pichai PERSON\n",
            "Google ORG\n",
            "Mountain View GPE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1LtwrnqQycmr"
      },
      "source": [
        "**Identifying people mentioned in a news article**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svn1P6CFylKh"
      },
      "source": [
        "# Load the required model\n",
        "nlp = spacy.load('en_core_web_sm')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxz9hMooymDP"
      },
      "source": [
        "tc = \"\\nItâ€™s' been a busy day for Facebook  exec op-eds. Earlier this morning, Sheryl Sandberg broke the siteâ€™s silence around the Christchurch massacre, and now Mark Zuckerberg is calling on governments and other bodies to increase regulation around the sorts of data Facebook traffics in. Heâ€™s hoping to get out in front of heavy-handed regulation and get a seat at the table shaping it.\\n\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRlXgD8myokS"
      },
      "source": [
        "def find_persons(text):\n",
        "  # Create Doc object\n",
        "  doc = nlp(text)\n",
        "\n",
        "  # Identify the persons\n",
        "  persons = [ent.text for ent in doc.ents if ent.label_ == 'PERSON']\n",
        "\n",
        "  # Return persons\n",
        "  return persons"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MDJmx2n0yrRS",
        "outputId": "4904843d-86e4-44a6-855f-b05b8b1bc144"
      },
      "source": [
        "print(find_persons(tc))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Sheryl Sandberg', 'Mark Zuckerberg']\n"
          ]
        }
      ]
    }
  ]
}